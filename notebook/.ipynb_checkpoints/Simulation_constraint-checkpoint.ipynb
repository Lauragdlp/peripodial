{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f21f9f32-0ef9-4459-bb5e-b821976fbfbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Could not load OpenGL library.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vispy  won't work\n"
     ]
    }
   ],
   "source": [
    "# Import \n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import datetime\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import rcParams\n",
    "\n",
    "from pathlib import Path\n",
    "from tyssue import Sheet\n",
    "from tyssue.io import hdf5\n",
    "\n",
    "from tyssue.dynamics.sheet_gradients import height_grad\n",
    "from tyssue.dynamics import units, effectors, model_factory\n",
    "from tyssue.solvers.quasistatic import QSSolver\n",
    "from tyssue.draw import sheet_view\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "rcParams['figure.dpi'] = 200\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from peripodial.polarity import model\n",
    "from peripodial.dynamics import EllipsoidLameGeometry as geom\n",
    "from peripodial.anisotropy import anysotropy as aniso\n",
    "from peripodial.anisotropy import face_orientation\n",
    "from peripodial.polarity import update_weights\n",
    "from peripodial.draw import draw_half_N_sheet\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfe8aed1-4867-4696-88d8-db3e68656dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f06fdf98-0917-4e34-aca6-e6a326d33d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "dsets = hdf5.load_datasets('../json_hdf5/lumen_elasticity.hdf5',\n",
    "                               data_names=['vert', 'edge', 'face'])\n",
    "\n",
    "with open('../json_hdf5/lumen_elasticity.json', 'r+') as fp:\n",
    "    specs = json.load(fp)\n",
    "\n",
    "sheet = Sheet('spherical', dsets)\n",
    "\n",
    "sheet.update_specs(specs)\n",
    "geom.update_all(sheet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8aa391b0-6476-422a-b361-8cc32afec161",
   "metadata": {},
   "outputs": [],
   "source": [
    "specs = {'face': {'prefered_perimeter': 3.8},\n",
    " 'settings': {'geometry': 'spherical',\n",
    "  'height_axis': 'z',\n",
    "  'lumen_prefered_vol': 5700,\n",
    "  'lumen_vol_elasticity': 0.01,\n",
    "  'threshold_length': 0.01,\n",
    "  'rosette_kwargs': {'threshold_length': 0.01, 'p_4': 0.01, 'p_5': 0.001},\n",
    "  'barrier_radius': 13},\n",
    " 'vert': {'barrier_elasticity': 280, 'delta_rho': 0},\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "824de9f3-f139-4594-9b9f-003820372a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "els_lumen, els_barrier = np.meshgrid(np.linspace(1e-4, 1e-2, 10), np.linspace(0.0, 0.4, 10))\n",
    "\n",
    "diameters = {}\n",
    "middle_dia_s = {}\n",
    "aniso_cell_values_d = {}\n",
    "\n",
    "metrics = {\n",
    "    \"diameters\": diameters,\n",
    "    \"middle_dia_s\": middle_dia_s,\n",
    "    \"aniso_cell_values_d\": aniso_cell_values_d\n",
    "}\n",
    "\n",
    "\n",
    "def multi_parameters(l, b):\n",
    "    solver = QSSolver(with_t1=False, with_t3=False)\n",
    "    sheet_copy = sheet.copy()\n",
    "    sheet_copy.settings['lumen_vol_elasticity']= l\n",
    "    sheet_copy.vert_df['barrier_elasticity'] = be\n",
    "    res = solver.find_energy_min(sheet_copy, geom, model, options={\"gtol\": 1e-8})\n",
    "    diameter = 2*(sheet.vert_df[\"z\"].max())\n",
    "    diameters[l, b] = diameter\n",
    "    center_verts =  sheet_copy.vert_df.loc[np.abs(sheet.vert_df[\"z\"]) < 1]\n",
    "    middle_dia = 2*(center_verts[\"x\"]**2 + center_verts[\"y\"]**2)**(0.5)\n",
    "    middle_dia_s[l, b] = middle_dia \n",
    "    sheet_copy.face_df['anisotropy'] = aniso(sheet_copy, coords = ['x','y','z'])\n",
    "    center = np.abs(sheet_copy.face_df[\"z\"]) < sheet_copy.face_df[\"z\"].max()*0.75\n",
    "    aniso_cell = sheet_copy.face_df.loc[center, 'anisotropy'].mean()\n",
    "    aniso_cell_values_d[l, b] = aniso_cell\n",
    "    \n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40762db7-1233-4b37-8784-97398b88d59c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1 / 100\n",
      "Processing 2 / 100\n",
      "Processing 3 / 100\n",
      "Processing 4 / 100\n",
      "Processing 5 / 100\n",
      "Processing 6 / 100\n",
      "Processing 7 / 100\n",
      "Processing 8 / 100\n",
      "Processing 9 / 100\n",
      "Processing 10 / 100\n",
      "Processing 11 / 100\n",
      "Processing 12 / 100\n",
      "Processing 13 / 100\n",
      "Processing 14 / 100\n",
      "Processing 15 / 100\n",
      "Processing 16 / 100\n",
      "Processing 17 / 100\n",
      "Processing 18 / 100\n",
      "Processing 19 / 100\n",
      "Processing 20 / 100\n",
      "Processing 21 / 100\n",
      "Processing 22 / 100\n",
      "Processing 23 / 100\n",
      "Processing 24 / 100\n",
      "Processing 25 / 100\n",
      "Processing 26 / 100\n",
      "Processing 27 / 100\n",
      "Processing 28 / 100\n",
      "Processing 29 / 100\n",
      "Processing 30 / 100\n",
      "Processing 31 / 100\n",
      "Processing 32 / 100\n",
      "Processing 33 / 100\n",
      "Processing 34 / 100\n",
      "Processing 35 / 100\n",
      "Processing 36 / 100\n",
      "Processing 37 / 100\n",
      "Processing 38 / 100\n",
      "Processing 39 / 100\n",
      "Processing 40 / 100\n",
      "Processing 41 / 100\n",
      "Processing 42 / 100\n",
      "Processing 43 / 100\n",
      "Processing 44 / 100\n",
      "Processing 45 / 100\n",
      "Processing 46 / 100\n",
      "Processing 47 / 100\n",
      "Processing 48 / 100\n",
      "Processing 49 / 100\n",
      "Processing 50 / 100\n",
      "Processing 51 / 100\n",
      "Processing 52 / 100\n",
      "Processing 53 / 100\n",
      "Processing 54 / 100\n",
      "Processing 55 / 100\n",
      "Processing 56 / 100\n",
      "Processing 57 / 100\n",
      "Processing 58 / 100\n",
      "Processing 59 / 100\n",
      "Processing 60 / 100\n",
      "Processing 61 / 100\n",
      "Processing 62 / 100\n",
      "Processing 63 / 100\n",
      "Processing 64 / 100\n",
      "Processing 65 / 100\n",
      "Processing 66 / 100\n",
      "Processing 67 / 100\n",
      "Processing 68 / 100\n",
      "Processing 69 / 100\n",
      "Processing 70 / 100\n",
      "Processing 71 / 100\n",
      "Processing 72 / 100\n",
      "Processing 73 / 100\n",
      "Processing 74 / 100\n",
      "Processing 75 / 100\n",
      "Processing 76 / 100\n",
      "Processing 77 / 100\n",
      "Processing 78 / 100\n",
      "Processing 79 / 100\n",
      "Processing 80 / 100\n",
      "Processing 81 / 100\n",
      "Processing 82 / 100\n",
      "Processing 83 / 100\n",
      "Processing 84 / 100\n",
      "Processing 85 / 100\n",
      "Processing 86 / 100\n",
      "Processing 87 / 100\n",
      "Processing 88 / 100\n",
      "Processing 89 / 100\n",
      "Processing 90 / 100\n",
      "Processing 91 / 100\n",
      "Processing 92 / 100\n",
      "Processing 93 / 100\n",
      "Processing 94 / 100\n",
      "Processing 95 / 100\n",
      "Processing 96 / 100\n",
      "Processing 97 / 100\n",
      "Processing 98 / 100\n",
      "Processing 99 / 100\n",
      "Processing 100 / 100\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i, (l, b) in enumerate(zip(els_lumen.ravel(), els_barrier.ravel())):\n",
    "    print(f\"Processing {i+1} / {len(els_lumen.ravel())}\")\n",
    "    filename = f\"../json_hdf5/Simulation/measures_l{round(l, 5)}_b{round(b, 5)}.json\"\n",
    "    with Path(filename).open(\"w\") as fh:\n",
    "        json.dump(metrics, fh, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67b3e71d-0017-4268-a46e-f4ea74ef2cb4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'be' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/lglepin/miniconda3/envs/tyssue/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py\", line 463, in _process_worker\n    r = call_item()\n  File \"/home/lglepin/miniconda3/envs/tyssue/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py\", line 291, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"/home/lglepin/miniconda3/envs/tyssue/lib/python3.10/site-packages/joblib/parallel.py\", line 598, in __call__\n    return [func(*args, **kwargs)\n  File \"/home/lglepin/miniconda3/envs/tyssue/lib/python3.10/site-packages/joblib/parallel.py\", line 598, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"/tmp/ipykernel_11238/3195319736.py\", line 18, in multi_parameters\nNameError: name 'be' is not defined\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmulti_parameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43ml\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ml\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mels_lumen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mels_barrier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Convert results to DataFrame\u001b[39;00m\n\u001b[1;32m      3\u001b[0m df_results \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame\u001b[38;5;241m.\u001b[39mfrom_records(results)\n",
      "File \u001b[0;32m~/miniconda3/envs/tyssue/lib/python3.10/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tyssue/lib/python3.10/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tyssue/lib/python3.10/site-packages/joblib/parallel.py:1754\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_retrieval():\n\u001b[1;32m   1748\u001b[0m \n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;66;03m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m     \u001b[38;5;66;03m# triggered an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[1;32m   1751\u001b[0m     \u001b[38;5;66;03m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[1;32m   1752\u001b[0m     \u001b[38;5;66;03m# worker traceback.\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aborting:\n\u001b[0;32m-> 1754\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_error_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1755\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1757\u001b[0m     \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m     \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tyssue/lib/python3.10/site-packages/joblib/parallel.py:1789\u001b[0m, in \u001b[0;36mParallel._raise_error_fast\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1785\u001b[0m \u001b[38;5;66;03m# If this error job exists, immediatly raise the error by\u001b[39;00m\n\u001b[1;32m   1786\u001b[0m \u001b[38;5;66;03m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m \u001b[38;5;66;03m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[1;32m   1788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1789\u001b[0m     \u001b[43merror_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tyssue/lib/python3.10/site-packages/joblib/parallel.py:745\u001b[0m, in \u001b[0;36mBatchCompletionCallBack.get_result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    739\u001b[0m backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel\u001b[38;5;241m.\u001b[39m_backend\n\u001b[1;32m    741\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39msupports_retrieve_callback:\n\u001b[1;32m    742\u001b[0m     \u001b[38;5;66;03m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[1;32m    743\u001b[0m     \u001b[38;5;66;03m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[1;32m    744\u001b[0m     \u001b[38;5;66;03m# be returned.\u001b[39;00m\n\u001b[0;32m--> 745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_return_or_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;66;03m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n\u001b[1;32m    748\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/tyssue/lib/python3.10/site-packages/joblib/parallel.py:763\u001b[0m, in \u001b[0;36mBatchCompletionCallBack._return_or_raise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    762\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m TASK_ERROR:\n\u001b[0;32m--> 763\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[1;32m    764\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[1;32m    765\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'be' is not defined"
     ]
    }
   ],
   "source": [
    "result = Parallel(n_jobs=2)(delayed(multi_parameters)(l, b) for l, b in zip(els_lumen.ravel(), els_barrier.ravel()))\n",
    "# Convert results to DataFrame\n",
    "df_results = pd.DataFrame.from_records(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696a7327-0166-4a5b-be43-c918d5c56716",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
